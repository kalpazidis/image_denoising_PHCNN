{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial: Parameterized Hypercomplex Multiplication (PHM) Layer\n",
    "\n",
    "#### Author: Eleonora Grassucci\n",
    "\n",
    "Original paper: Beyond Fully-Connected Layers with Quaternions: Parameterization of Hypercomplex Multiplications with 1/n Parameters.\n",
    "\n",
    "Aston Zhang, Yi Tay, Shuai Zhang, Alvin Chan, Anh Tuan Luu, Siu Cheung Hui, Jie Fu.\n",
    "\n",
    "[ArXiv link](https://arxiv.org/pdf/2102.08597.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1+cu102'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Pytorch version: torch.kron is available from 1.8.0\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the PHM class\n",
    "\n",
    "class PHM(nn.Module):\n",
    "    '''\n",
    "    Simple PHM Module, the only parameter is A, since S is passed from the trainset.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, n, kernel_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.n = n\n",
    "        A = torch.empty((n-1, n, n))\n",
    "        self.A = nn.Parameter(A)\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def forward(self, X, S):\n",
    "        H = torch.zeros((self.n*self.kernel_size, self.n*self.kernel_size))\n",
    "        \n",
    "        # Sum of Kronecker products\n",
    "        for i in range(n-1):\n",
    "            H = H + torch.kron(self.A[i], S[i])\n",
    "        return torch.matmul(X, H.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Hamilton product between two pure quaternions\n",
    "\n",
    "A pure quaternion is a quaternion with scalar part equal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the training set\n",
    "\n",
    "x = torch.FloatTensor([0, 1, 2, 3]).view(4, 1) # Scalar part equal to 0\n",
    "W = torch.FloatTensor([[0,-1,-1,-1], [1,0,-1,1], [1,1,0,-1], [1,-1,1,0]]) # Scalar parts equal to 0\n",
    "\n",
    "y = torch.matmul(W, x)\n",
    "\n",
    "num_examples = 1000\n",
    "batch_size = 1\n",
    "\n",
    "X = torch.zeros((num_examples, 16))\n",
    "S = torch.zeros((num_examples, 16))\n",
    "Y = torch.zeros((num_examples, 16))\n",
    "\n",
    "for i in range(num_examples):\n",
    "    x = torch.randint(low=-10, high=10, size=(12, ), dtype=torch.float)\n",
    "    s = torch.randint(low=-10, high=10, size=(12, ), dtype=torch.float)\n",
    "    \n",
    "    s1, s2, s3, s4 = torch.FloatTensor([0]*4), s[0:4], s[4:8], s[8:12]\n",
    "    s1 = s1.view(2,2)\n",
    "    s2 = s2.view(2,2)\n",
    "    s3 = s3.view(2,2)\n",
    "    s4 = s4.view(2,2)\n",
    "\n",
    "    s_1 = torch.cat([s1,-s2,-s3,-s4])\n",
    "    s_2 = torch.cat([s2,s1,-s4,s3])\n",
    "    s_3 = torch.cat([s3,s4,s1,-s2])\n",
    "    s_4 = torch.cat([s4,-s3,s2,s1])\n",
    "\n",
    "    W = torch.cat([s_1,s_2, s_3, s_4], dim=1) \n",
    "    x = torch.cat([torch.FloatTensor([0]*4), x])\n",
    "    s = torch.cat([torch.FloatTensor([0]*4), s])\n",
    "    x_mult = x.view(2, 8)\n",
    "    y = torch.matmul(x_mult, W.T)    \n",
    "    y = y.view(16, )\n",
    "\n",
    "    X[i, :] = x\n",
    "    S[i, :] = s\n",
    "    Y[i, :] = y\n",
    "\n",
    "X = torch.FloatTensor(X).view(num_examples, 16, 1)\n",
    "S = torch.FloatTensor(S).view(num_examples, 16, 1)\n",
    "Y = torch.FloatTensor(Y).view(num_examples, 16, 1)\n",
    "\n",
    "data = torch.cat([X, S, Y], dim=2)\n",
    "train_iter = torch.utils.data.DataLoader(data, batch_size=batch_size)\n",
    "\n",
    "### Setup the test set\n",
    "\n",
    "num_examples = 1\n",
    "batch_size = 1\n",
    "\n",
    "X = torch.zeros((num_examples, 16))\n",
    "S = torch.zeros((num_examples, 16))\n",
    "Y = torch.zeros((num_examples, 16))\n",
    "\n",
    "for i in range(num_examples):\n",
    "    x = torch.randint(low=-10, high=10, size=(12, ), dtype=torch.float)\n",
    "    s = torch.randint(low=-10, high=10, size=(12, ), dtype=torch.float)\n",
    "    \n",
    "    s1, s2, s3, s4 = torch.FloatTensor([0]*4), s[0:4], s[4:8], s[8:12]\n",
    "    s1 = s1.view(2,2)\n",
    "    s2 = s2.view(2,2)\n",
    "    s3 = s3.view(2,2)\n",
    "    s4 = s4.view(2,2)\n",
    "\n",
    "    s_1 = torch.cat([s1,-s2,-s3,-s4])\n",
    "    s_2 = torch.cat([s2,s1,-s4,s3])\n",
    "    s_3 = torch.cat([s3,s4,s1,-s2])\n",
    "    s_4 = torch.cat([s4,-s3,s2,s1])\n",
    "\n",
    "    W = torch.cat([s_1,s_2, s_3, s_4], dim=1) \n",
    "    x = torch.cat([torch.FloatTensor([0]*4), x])\n",
    "    s = torch.cat([torch.FloatTensor([0]*4), s])\n",
    "    x_mult = x.view(2, 8)\n",
    "    y = torch.matmul(x_mult, W.T)    \n",
    "    y = y.view(16, )\n",
    "\n",
    "    X[i, :] = x\n",
    "    S[i, :] = s\n",
    "    Y[i, :] = y\n",
    "\n",
    "X = torch.FloatTensor(X).view(num_examples, 16, 1)\n",
    "S = torch.FloatTensor(S).view(num_examples, 16, 1)\n",
    "Y = torch.FloatTensor(Y).view(num_examples, 16, 1)\n",
    "\n",
    "data = torch.cat([X, S, Y], dim=2)\n",
    "test_iter = torch.utils.data.DataLoader(data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training function\n",
    "\n",
    "def train(net, lr, phm=True):\n",
    "    # Squared loss\n",
    "    loss = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(5):\n",
    "        for data in train_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X = data[:, :, 0]\n",
    "            S = data[:, 4:, 1]\n",
    "            Y = data[:, :, 2]\n",
    "            \n",
    "            if phm:\n",
    "                out = net(X.view(2, 8), S.view(3, 2, 2))\n",
    "            else:\n",
    "                out = net(X)\n",
    "            \n",
    "            l = loss(out, Y.view(2, 8))\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "        print(f'epoch {epoch + 1}, loss {float(l.sum() / batch_size):.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.021605\n",
      "epoch 2, loss 0.000000\n",
      "epoch 3, loss 0.000000\n",
      "epoch 4, loss 0.000000\n",
      "epoch 5, loss 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Initialize model parameters\n",
    "def weights_init_uniform(m):\n",
    "    m.A.data.uniform_(-0.07, 0.07)\n",
    "    \n",
    "# Create layer instance\n",
    "n = 4\n",
    "phm_layer = PHM(n, kernel_size=2)\n",
    "phm_layer.apply(weights_init_uniform)\n",
    "\n",
    "# Train the model\n",
    "train(phm_layer, 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A tensor([[[-6.0884e-08,  1.0000e+00, -1.6100e-08,  2.6916e-08],\n",
      "         [-1.0000e+00, -1.8684e-08, -2.1245e-08, -8.8355e-08],\n",
      "         [-1.2780e-08,  1.2693e-07, -3.8119e-08,  1.0000e+00],\n",
      "         [-1.0182e-07,  4.7619e-08, -1.0000e+00,  3.8946e-08]],\n",
      "\n",
      "        [[ 1.5405e-08, -3.1784e-08,  1.0000e+00,  2.9003e-08],\n",
      "         [-3.5486e-08, -3.5375e-08,  3.3766e-08, -1.0000e+00],\n",
      "         [-1.0000e+00, -2.9093e-08, -5.3595e-08,  3.2789e-08],\n",
      "         [ 6.2255e-09,  1.0000e+00,  3.7168e-08,  8.2059e-09]],\n",
      "\n",
      "        [[-3.9100e-08, -5.8766e-09,  2.8090e-09,  1.0000e+00],\n",
      "         [-1.5466e-07,  5.3471e-08,  1.0000e+00,  3.3222e-08],\n",
      "         [ 3.3584e-08, -1.0000e+00, -6.5275e-08,  1.9724e-07],\n",
      "         [-1.0000e+00, -3.0299e-08,  1.3472e-08, -2.8102e-08]]])\n"
     ]
    }
   ],
   "source": [
    "# Check parameters of the layer require grad\n",
    "for name, param in phm_layer.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamilton product result from test set:\n",
      " tensor([[  82., -198.,    2.,   70.,   -4.,   54., -160.,   52.],\n",
      "        [  51.,   45., -133.,   86., -103.,  225., -125.,   92.]])\n",
      "Performing Hamilton product learned by PHM:\n",
      " tensor([[  82.0000, -198.0000,    2.0000,   70.0000,   -4.0000,   54.0000,\n",
      "         -160.0000,   52.0000],\n",
      "        [  51.0000,   45.0000, -133.0000,   86.0000, -103.0000,  225.0001,\n",
      "         -125.0000,   92.0000]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the convolution performed on the test set\n",
    "\n",
    "for data in test_iter:\n",
    "    X = data[:, :, 0]\n",
    "    S = data[:, 4:, 1]\n",
    "    Y = data[:, :, 2]\n",
    "\n",
    "    y_phm = phm_layer(X.view(2, 8), S.view(3, 2, 2))\n",
    "    \n",
    "    print('Hamilton product result from test set:\\n', Y.view(2, 8))\n",
    "    print('Performing Hamilton product learned by PHM:\\n', y_phm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground-truth Hamilton product matrix:\n",
      " tensor([[ 0., -1., -1., -1.],\n",
      "        [ 1.,  0., -1.,  1.],\n",
      "        [ 1.,  1.,  0., -1.],\n",
      "        [ 1., -1.,  1.,  0.]])\n",
      "\n",
      "Learned A in PHM:\n",
      " Parameter containing:\n",
      "tensor([[[-6.0884e-08,  1.0000e+00, -1.6100e-08,  2.6916e-08],\n",
      "         [-1.0000e+00, -1.8684e-08, -2.1245e-08, -8.8355e-08],\n",
      "         [-1.2780e-08,  1.2693e-07, -3.8119e-08,  1.0000e+00],\n",
      "         [-1.0182e-07,  4.7619e-08, -1.0000e+00,  3.8946e-08]],\n",
      "\n",
      "        [[ 1.5405e-08, -3.1784e-08,  1.0000e+00,  2.9003e-08],\n",
      "         [-3.5486e-08, -3.5375e-08,  3.3766e-08, -1.0000e+00],\n",
      "         [-1.0000e+00, -2.9093e-08, -5.3595e-08,  3.2789e-08],\n",
      "         [ 6.2255e-09,  1.0000e+00,  3.7168e-08,  8.2059e-09]],\n",
      "\n",
      "        [[-3.9100e-08, -5.8766e-09,  2.8090e-09,  1.0000e+00],\n",
      "         [-1.5466e-07,  5.3471e-08,  1.0000e+00,  3.3222e-08],\n",
      "         [ 3.3584e-08, -1.0000e+00, -6.5275e-08,  1.9724e-07],\n",
      "         [-1.0000e+00, -3.0299e-08,  1.3472e-08, -2.8102e-08]]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Learned A sum in PHM:\n",
      " tensor([[-8.4579e-08, -1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
      "        [ 1.0000e+00, -5.8745e-10, -1.0000e+00,  1.0000e+00],\n",
      "        [ 1.0000e+00,  1.0000e+00, -1.5699e-07, -1.0000e+00],\n",
      "        [ 1.0000e+00, -1.0000e+00,  1.0000e+00,  1.9049e-08]],\n",
      "       grad_fn=<PermuteBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Check the PHC layer have learnt the proper algebra for the marix A\n",
    "\n",
    "W = torch.FloatTensor([[0,-1,-1,-1], [1,0,-1,1], [1,1,0,-1], [1,-1,1,0]])\n",
    "\n",
    "print('Ground-truth Hamilton product matrix:\\n', W)\n",
    "print()\n",
    "print('Learned A in PHM:\\n', phm_layer.A)\n",
    "print()\n",
    "print('Learned A sum in PHM:\\n', sum(phm_layer.A).T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

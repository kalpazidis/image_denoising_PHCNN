{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial: Parameterized Hypercomplex Convolutional (PHC) Layer\n",
    "\n",
    "#### Author: Eleonora Grassucci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import imageio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.nn import init\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1+cu102'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Pytorch version: torch.kron is available from 1.8.0\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the PHC class\n",
    "\n",
    "class PHC(nn.Module):\n",
    "    '''\n",
    "    Simple PHC Module, the only parameter is A, since F is passed from the trainset.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n, kernel_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.n = n\n",
    "        A = torch.empty((n, n, n))\n",
    "        self.A = nn.Parameter(A)\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def forward(self, X, S):\n",
    "        H = torch.zeros((self.n*self.kernel_size, self.n*self.kernel_size))\n",
    "        \n",
    "        # Sum of Kronecker products\n",
    "        for i in range(n):\n",
    "            H = H + torch.kron(self.A[i], S[i])\n",
    "        H = H.view(4, 4, 2, 2)\n",
    "        return torch.nn.functional.conv2d(X, H, padding=2, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the training set\n",
    "\n",
    "num_examples = 1000\n",
    "batch_size = 1\n",
    "\n",
    "X = torch.zeros((num_examples, 64)) #1x4x4x4\n",
    "F = torch.zeros((num_examples, 64)) #4x4x2x2\n",
    "Y = torch.zeros((num_examples, 64)) #1x4x4x4\n",
    "\n",
    "for i in range(num_examples):\n",
    "    # Iterate to create the dataset\n",
    "    x = torch.randint(low=-10, high=10, size=(64, ), dtype=torch.float)\n",
    "    f = torch.randint(low=-10, high=10, size=(16, ), dtype=torch.float)\n",
    "\n",
    "    f1, f2, f3, f4 = f[0:4], f[4:8], f[8:12], f[12:16]\n",
    "    f1 = f1.view(2,2)\n",
    "    f2 = f2.view(2,2)\n",
    "    f3 = f3.view(2,2)\n",
    "    f4 = f4.view(2,2)\n",
    "\n",
    "    # Hamilton product rule\n",
    "    f_1 = torch.cat([f1,-f2,-f3,-f4])\n",
    "    f_2 = torch.cat([f2,f1,-f4,f3])\n",
    "    f_3 = torch.cat([f3,f4,f1,-f2])\n",
    "    f_4 = torch.cat([f4,-f3,f2,f1])\n",
    "\n",
    "    W = torch.cat([f_1, f_2, f_3, f_4], dim=1)    \n",
    "    W_conv = W.view(4, 4, 2, 2)\n",
    "    x_conv = x.view(1, 4, 4, 4)\n",
    "\n",
    "    # Apply convolution from inputx x_conv and filters W_conv\n",
    "    y = torch.nn.functional.conv2d(x_conv, W_conv, padding=2, stride=2)\n",
    "    y = y.view(64, )\n",
    "    f_loader = torch.cat([f, torch.zeros(48)])\n",
    "\n",
    "    X[i, :] = x\n",
    "    F[i, :] = f_loader\n",
    "    Y[i, :] = y\n",
    "\n",
    "X = torch.FloatTensor(X).view(num_examples, 64, 1)\n",
    "F = torch.FloatTensor(F).view(num_examples, 64, 1)\n",
    "Y = torch.FloatTensor(Y).view(num_examples, 64, 1)\n",
    "\n",
    "data = torch.cat([X, F, Y], dim=2)\n",
    "train_iter = torch.utils.data.DataLoader(data, batch_size=batch_size)\n",
    "\n",
    "# Setup the test set\n",
    "\n",
    "num_examples = 1\n",
    "batch_size = 1\n",
    "\n",
    "X = torch.zeros((num_examples, 64)) #1x4x4x4\n",
    "F = torch.zeros((num_examples, 64)) #4x4x2x2\n",
    "Y = torch.zeros((num_examples, 64)) #1x4x4x4\n",
    "\n",
    "for i in range(num_examples):\n",
    "    x = torch.randint(low=-10, high=10, size=(64, ), dtype=torch.float)\n",
    "    f = torch.randint(low=-10, high=10, size=(16, ), dtype=torch.float)\n",
    "\n",
    "    f1, f2, f3, f4 = f[0:4], f[4:8], f[8:12], f[12:16]\n",
    "    f1 = f1.view(2,2)\n",
    "    f2 = f2.view(2,2)\n",
    "    f3 = f3.view(2,2)\n",
    "    f4 = f4.view(2,2)\n",
    "\n",
    "    f_1 = torch.cat([f1,-f2,-f3,-f4])\n",
    "    f_2 = torch.cat([f2,f1,-f4,f3])\n",
    "    f_3 = torch.cat([f3,f4,f1,-f2])\n",
    "    f_4 = torch.cat([f4,-f3,f2,f1])\n",
    "\n",
    "    W = torch.cat([f_1, f_2, f_3, f_4], dim=1)    \n",
    "    W_conv = W.view(4, 4, 2, 2)\n",
    "    x_conv = x.view(1, 4, 4, 4)\n",
    "\n",
    "    #     y = torch.matmul(x_mult, W.T)\n",
    "    y = torch.nn.functional.conv2d(x_conv, W_conv, padding=2, stride=2)\n",
    "    y = y.view(64, )\n",
    "    f_loader = torch.cat([f, torch.zeros(48)])\n",
    "\n",
    "    X[i, :] = x\n",
    "    F[i, :] = f_loader\n",
    "    Y[i, :] = y\n",
    "\n",
    "X = torch.FloatTensor(X).view(num_examples, 64, 1)\n",
    "F = torch.FloatTensor(F).view(num_examples, 64, 1)\n",
    "Y = torch.FloatTensor(Y).view(num_examples, 64, 1)\n",
    "\n",
    "data = torch.cat([X, F, Y], dim=2)\n",
    "test_iter = torch.utils.data.DataLoader(data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training function\n",
    "\n",
    "def train(net, lr, phm=True):\n",
    "    # Squared loss\n",
    "    loss = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(5):\n",
    "        for data in train_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X = data[:, :, 0]\n",
    "            F = data[:, :16, 1]\n",
    "            Y = data[:, :, 2]\n",
    "            \n",
    "            if phm:\n",
    "                out = net(X.view(1, 4, 4, 4), F.view(4, 2, 2))\n",
    "            else:\n",
    "                out = net(X)\n",
    "            \n",
    "            l = loss(out, Y.view(1, 4, 4, 4))\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "        print(f'epoch {epoch + 1}, loss {float(l.sum() / batch_size):.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.013041\n",
      "epoch 2, loss 0.000000\n",
      "epoch 3, loss 0.000000\n",
      "epoch 4, loss 0.000000\n",
      "epoch 5, loss 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Perform training\n",
    "\n",
    "# Initialize weights\n",
    "def weights_init_uniform(m):\n",
    "    m.A.data.uniform_(-0.07, 0.07)\n",
    "    \n",
    "# Setup the parameter n\n",
    "n = 4\n",
    "# Create an instance of the layer\n",
    "phc_layer = PHC(n, kernel_size=2)\n",
    "phc_layer.apply(weights_init_uniform)\n",
    "# torch.nn.init.xavier_uniform_(phm_layer.A)\n",
    "\n",
    "train(phc_layer, 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A tensor([[[ 1.0000e+00, -3.4842e-08,  9.3512e-09, -5.0719e-09],\n",
      "         [-2.0920e-08,  1.0000e+00, -1.4429e-07, -1.2676e-08],\n",
      "         [-6.9660e-08,  2.9980e-09,  1.0000e+00, -7.5538e-08],\n",
      "         [-3.6260e-08,  3.3173e-08, -7.2906e-08,  1.0000e+00]],\n",
      "\n",
      "        [[ 5.1754e-08,  1.0000e+00,  1.1234e-07, -4.6763e-08],\n",
      "         [-1.0000e+00,  1.3011e-07, -1.1934e-08, -2.5277e-08],\n",
      "         [-8.2055e-08,  5.1245e-08,  6.2276e-08,  1.0000e+00],\n",
      "         [ 1.0933e-08, -7.0609e-08, -1.0000e+00,  1.5147e-08]],\n",
      "\n",
      "        [[ 4.0813e-08,  4.1984e-08,  1.0000e+00, -7.7404e-09],\n",
      "         [-7.8505e-09,  9.8508e-09, -5.7320e-08, -1.0000e+00],\n",
      "         [-1.0000e+00,  1.7232e-08,  1.1296e-08, -3.2608e-08],\n",
      "         [ 4.0355e-08,  1.0000e+00, -5.0336e-08,  6.4603e-09]],\n",
      "\n",
      "        [[ 3.8183e-08,  8.0717e-08, -2.0061e-08,  1.0000e+00],\n",
      "         [ 6.4894e-08, -2.9346e-08,  1.0000e+00, -4.8612e-08],\n",
      "         [-7.3210e-08, -1.0000e+00,  3.0607e-08,  4.8066e-08],\n",
      "         [-1.0000e+00, -1.3118e-08, -1.4183e-08,  4.7255e-08]]])\n"
     ]
    }
   ],
   "source": [
    "# check parameters of the layer require grad\n",
    "for name, param in phc_layer.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution from test set:\n",
      " tensor([[[[   0.,    0.,    0.,    0.],\n",
      "          [   0.,  -99., -165.,    0.],\n",
      "          [   0.,    4., -286.,    0.],\n",
      "          [   0.,    0.,    0.,    0.]],\n",
      "\n",
      "         [[   0.,    0.,    0.,    0.],\n",
      "          [   0., -138.,  102.,    0.],\n",
      "          [   0., -246.,  -23.,    0.],\n",
      "          [   0.,    0.,    0.,    0.]],\n",
      "\n",
      "         [[   0.,    0.,    0.,    0.],\n",
      "          [   0.,  -28.,  352.,    0.],\n",
      "          [   0.,  250., -142.,    0.],\n",
      "          [   0.,    0.,    0.,    0.]],\n",
      "\n",
      "         [[   0.,    0.,    0.,    0.],\n",
      "          [   0., -183., -367.,    0.],\n",
      "          [   0.,  -69.,  -77.,    0.],\n",
      "          [   0.,    0.,    0.,    0.]]]])\n",
      "Performing convolution learned by PHC:\n",
      " tensor([[[[   0.0000,    0.0000,    0.0000,    0.0000],\n",
      "          [   0.0000,  -99.0000, -165.0000,    0.0000],\n",
      "          [   0.0000,    4.0000, -286.0000,    0.0000],\n",
      "          [   0.0000,    0.0000,    0.0000,    0.0000]],\n",
      "\n",
      "         [[   0.0000,    0.0000,    0.0000,    0.0000],\n",
      "          [   0.0000, -138.0000,  102.0000,    0.0000],\n",
      "          [   0.0000, -246.0000,  -23.0000,    0.0000],\n",
      "          [   0.0000,    0.0000,    0.0000,    0.0000]],\n",
      "\n",
      "         [[   0.0000,    0.0000,    0.0000,    0.0000],\n",
      "          [   0.0000,  -28.0000,  351.9999,    0.0000],\n",
      "          [   0.0000,  249.9999, -142.0000,    0.0000],\n",
      "          [   0.0000,    0.0000,    0.0000,    0.0000]],\n",
      "\n",
      "         [[   0.0000,    0.0000,    0.0000,    0.0000],\n",
      "          [   0.0000, -183.0000, -367.0000,    0.0000],\n",
      "          [   0.0000,  -69.0000,  -77.0000,    0.0000],\n",
      "          [   0.0000,    0.0000,    0.0000,    0.0000]]]],\n",
      "       grad_fn=<ThnnConv2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the convolution performed on the test set\n",
    "\n",
    "for data in test_iter:\n",
    "    X = data[:, :, 0]\n",
    "    F = data[:, :16, 1]\n",
    "    Y = data[:, :, 2]\n",
    "    \n",
    "    \n",
    "    y_phc = phc_layer(X.view(1, 4, 4, 4), F.view(4, 2, 2))\n",
    "    \n",
    "    print('Convolution from test set:\\n', Y.view(1, 4, 4, 4))\n",
    "    print('Performing convolution learned by PHC:\\n', y_phc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground-truth Hamilton rule:\n",
      " [[ 1 -1 -1 -1]\n",
      " [ 1  1 -1  1]\n",
      " [ 1  1  1 -1]\n",
      " [ 1 -1  1  1]]\n",
      "\n",
      "Learned A matrices in PHC:\n",
      " Parameter containing:\n",
      "tensor([[[ 1.0000e+00, -3.4842e-08,  9.3512e-09, -5.0719e-09],\n",
      "         [-2.0920e-08,  1.0000e+00, -1.4429e-07, -1.2676e-08],\n",
      "         [-6.9660e-08,  2.9980e-09,  1.0000e+00, -7.5538e-08],\n",
      "         [-3.6260e-08,  3.3173e-08, -7.2906e-08,  1.0000e+00]],\n",
      "\n",
      "        [[ 5.1754e-08,  1.0000e+00,  1.1234e-07, -4.6763e-08],\n",
      "         [-1.0000e+00,  1.3011e-07, -1.1934e-08, -2.5277e-08],\n",
      "         [-8.2055e-08,  5.1245e-08,  6.2276e-08,  1.0000e+00],\n",
      "         [ 1.0933e-08, -7.0609e-08, -1.0000e+00,  1.5147e-08]],\n",
      "\n",
      "        [[ 4.0813e-08,  4.1984e-08,  1.0000e+00, -7.7404e-09],\n",
      "         [-7.8505e-09,  9.8508e-09, -5.7320e-08, -1.0000e+00],\n",
      "         [-1.0000e+00,  1.7232e-08,  1.1296e-08, -3.2608e-08],\n",
      "         [ 4.0355e-08,  1.0000e+00, -5.0336e-08,  6.4603e-09]],\n",
      "\n",
      "        [[ 3.8183e-08,  8.0717e-08, -2.0061e-08,  1.0000e+00],\n",
      "         [ 6.4894e-08, -2.9346e-08,  1.0000e+00, -4.8612e-08],\n",
      "         [-7.3210e-08, -1.0000e+00,  3.0607e-08,  4.8066e-08],\n",
      "         [-1.0000e+00, -1.3118e-08, -1.4183e-08,  4.7255e-08]]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Learned final A in PHC:\n",
      " tensor([[ 1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [ 1.0000,  1.0000, -1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000, -1.0000],\n",
      "        [ 1.0000, -1.0000,  1.0000,  1.0000]], grad_fn=<PermuteBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Check the PHC layer have learnt the proper algebra for the marix A\n",
    "\n",
    "gt = np.array([[1, -1, -1, -1],\n",
    "      [1, 1, -1, 1],\n",
    "      [1, 1, 1, -1],\n",
    "      [1, -1, 1, 1]])\n",
    "\n",
    "print('Ground-truth Hamilton rule:\\n', gt)\n",
    "print()\n",
    "print('Learned A matrices in PHC:\\n', phc_layer.A)\n",
    "print()\n",
    "print('Learned final A in PHC:\\n', sum(phc_layer.A).T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
